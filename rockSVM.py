from sklearn.svm import SVC
from sklearn import preprocessing
import numpy as np
from utils import dataset
import os
import random

def main():
	path = os.getcwd() + '/dataset/nl_features_subset.csv'
	csv_reader = dataset.load_data(path)
	matrix = []
	for line in csv_reader:
		if "song" in line or "genre" in line or len(line) == 0:
			# Ignore the head of the csv and any empty lines
			continue
		
		currentSong = []
		for i in range(0, len(line)):
			# check to see if we are working with the genre
			if i == 0:
				# Include the name of the song
				currentSong.append(line[0])
			elif i == 1:
				if line[i] == "Rock":
					# 1 is rock
					currentSong.append(1)
				else:
					# 0 is not rock
					currentSong.append(0)
			else:
				currentSong.append(float(line[i]))

		matrix.append(currentSong)

	# Shuffle the matrix before separating into the feature matrix and the classification vector
	random.shuffle(matrix)

	#TODO: For testing purposes I probably want to include the name of the song as well so that we can go backwards and verify

	x = []
	y = []
	# Separate the matrix into the feature matrix and the classification vector
	for line in matrix:

		'''
		Ordering found in the CSV - song name has already been removed at this time, and genre is either Rock (1) or Not rock (0)
		0. Song Name - include song name so that we can go backwards
		1. genre
		2. annotations
		3. syllables
		4. syll_per_line
		5. verb
		6. adj
		7. noun
		8. pre-det
		9. det
		10. prep
		11. pronoun
		12. pos
		13. conj
		14. cardinal
		15. adverb
		16. particle
		17. exist
		18. inj
		19. aux
		20. rhyme scheme
		'''

		#TODO: Allow for different permutations of above to be ran

		x.append([float(line[2]), float(line[3]), float(line[4]), float(line[5]), float(line[6]), float(line[7]), float(line[8]), float(line[9]), float(line[10]), float(line[11]), float(line[12]), float(line[13]), float(line[14]), float(line[15]), float(line[16]), float(line[17]), float(line[18]), float(line[19])])
		# x.append([float(line[1]), float(line[2]), float(line[3]), float(line[4])])
		y.append(int(line[1]))
	x = np.asarray(x)
	y = np.asarray(y)

	# Scale the data matrix
	# Note: support vector machine algorithms are not scale invariant, so it is highly recommended to scale your data
	# For example, scale each attribute on the inmput vector X to [0,1] or [-1,1]
	x_scaled = preprocessing.scale(x)
	
	# to be used for training - x_train should be used with y_train (they should correspond with eachother)
	x_train = x_scaled[:800]
	y_train = y[:800]

	# to be used for testing - x_test should be used with y_test (they should correspond with eachother)
	x_test = x_scaled[800:]
	y_test = y[800:]

	clf = SVC(C = 1, kernel = "linear") # both linear and rbf appear to give an accuracy around 80%, decreasing the Slack Variable decreases accuracy
	clf.fit(x_train, y_train)
	
	# Individually test each of the points in the testing set
	answers = []
	for i in range(800,999):
		next = i+1
		answer = clf.predict(x_scaled[i: next])
		answers.append(answer[0])

	print("Answers generated by the SVM, length =", len(answers))
	print(answers)

	print("Answers defined by the dataset, length = ", len(y_test))
	print(y_test)

	# go through the matrix and retrieve the song names
	# song_names = []
	# for i in range(800,999):
	# 	line = matrix[i]
	# 	song_names.append(line[0])

	# print("The length of song names is: " + str(len(song_names)))
	# print(song_names)

	correct = 0
	test_rock_count = 0
	for i in range(0, len(y_test)):
		if answers[i] == y_test[i]:
			correct += 1
		if answers[i] == 1:
			test_rock_count += 1

	print("The actual number of rock songs found in the testing set", test_rock_count)

	print("My Calculated percentage: " + str(correct/len(y_test)))
	scr = clf.score(x_test, y_test)
	print("The percentage calculated by sci-kit Learn: " + str(scr))
	# for k in ['linear', 'poly', 'sigmoid', 'rbf']:
	# 	for i in range(1,100):

			# Setting C: c is 1 by default, and it's a reasonable default choice. If you have a lot of noisy observations, you should decrease it
			# it corresponds to regularize more the estimation
	# 		slack = float(i) / 10.0
	# 		clf = SVC(C = slack, kernel = k)

	# 		clf.fit(x_train, y_train)
	# 		answer = clf.predict(x_scaled[801:802])
	# 		print("Expected Answer: " + str(y[801:802]) + " Predicted answer",answer[0])
	# 		scr = clf.score(x_test, y_test)
	# 		print("\t",k, slack, scr, clf.support_vectors_.shape)

	


if __name__ == "__main__":
	main()
